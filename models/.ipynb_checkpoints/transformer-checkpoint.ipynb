{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "\n",
    "from torchtext import data\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.load_data import GLOVE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = data.Field(\n",
    "        tokenize = 'spacy'\n",
    "        , lower = True\n",
    "        , batch_first = True\n",
    ")\n",
    "\n",
    "target = data.Field(\n",
    "        sequential=False\n",
    "        , use_vocab = False\n",
    "        , is_target=True\n",
    ")\n",
    "\n",
    "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
    "    path = '/Users/janak/Documents/GitHub/mnli/utils/'\n",
    "    , train = 'train.csv'\n",
    "    , validation = 'val.csv'\n",
    "    , test = 'test.csv'\n",
    "    , format = 'csv'\n",
    "    , fields = {'sentence': ('text', source), 'gold_label': ('target', target)}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source.build_vocab(train_data, min_freq=2)\n",
    "source.vocab.load_vectors(torchtext.vocab.Vectors(GLOVE_PATH, cache=\".\"))\n",
    "\n",
    "print(source.vocab.vectors.shape)\n",
    "print(f\"Unique tokens in text vocabulary: {len(source.vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention is All You Need Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://nlp.seas.harvard.edu/2018/04/01/attention.html?fbclid=IwAR3xYCJaLYGXVgeCJBf1B_noXgciImPMz6caz0fE0eYEg2oDVShoey1iSL8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoder, decoder, src_embed, trg_embed, generator):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = src_embed\n",
    "        self.trg_embed = trg_embed\n",
    "        self.generator = generator\n",
    "    \n",
    "    def forward(self, src, trg, src_mask, trg_mask):\n",
    "        # Input masked source and target sequences\n",
    "        memory = self.encoder(self.src_embed(src), src_mask)\n",
    "        output = self.decoder(self.trg_embed(trg), memory, src_mask, trg_mask)\n",
    "    \n",
    "\"\"\"Encoder Stacks\"\"\"\n",
    "\n",
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "\n",
    "\"Pass the input (and mask) through each layer in turn.\"\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"Core encoder is a stack of N layers\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    \"Generic N layer decoder with masking.\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, src_mask, tgt_mask)\n",
    "        return self.norm(x)\n",
    "    \n",
    "# Residual Blocks:\n",
    "# https://towardsdatascience.com/residual-blocks-building-blocks-of-resnet-fd90ca15d6ec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
